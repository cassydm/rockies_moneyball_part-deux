{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align Prediction Features and Model-creation Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "from mega import model_df, unplayed_games\n",
    "\n",
    "df = model_df.copy()\n",
    "unplayed_games_clean = unplayed_games[3:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gm#</th>\n",
       "      <th>W/L</th>\n",
       "      <th>D/N</th>\n",
       "      <th>H/A</th>\n",
       "      <th>Opp</th>\n",
       "      <th>COL_at_bats</th>\n",
       "      <th>COL_ba</th>\n",
       "      <th>COL_hits</th>\n",
       "      <th>COL_hr</th>\n",
       "      <th>COL_kk</th>\n",
       "      <th>COL_obp</th>\n",
       "      <th>COL_walks</th>\n",
       "      <th>Opp_at_bats</th>\n",
       "      <th>Opp_ba</th>\n",
       "      <th>Opp_hits</th>\n",
       "      <th>OPP_HR_Column</th>\n",
       "      <th>OPP_kk</th>\n",
       "      <th>Opp_obp</th>\n",
       "      <th>Opp_walks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>MIL</td>\n",
       "      <td>31</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>W</td>\n",
       "      <td>N</td>\n",
       "      <td>A</td>\n",
       "      <td>MIL</td>\n",
       "      <td>32</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>W</td>\n",
       "      <td>N</td>\n",
       "      <td>A</td>\n",
       "      <td>MIL</td>\n",
       "      <td>34</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>W</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>SDP</td>\n",
       "      <td>33</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>W</td>\n",
       "      <td>N</td>\n",
       "      <td>H</td>\n",
       "      <td>SDP</td>\n",
       "      <td>33</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gm# W/L D/N H/A  Opp  COL_at_bats    COL_ba  COL_hits  COL_hr  COL_kk  \\\n",
       "0    1   L   D   A  MIL           31  0.258065         8       1       8   \n",
       "1    2   W   N   A  MIL           32  0.281250         9       1       5   \n",
       "2    3   W   N   A  MIL           34  0.264706         9       1       5   \n",
       "3    4   W   D   H  SDP           33  0.212121         7       0       8   \n",
       "4    5   W   N   H  SDP           33  0.242424         8       0       4   \n",
       "\n",
       "    COL_obp  COL_walks  Opp_at_bats    Opp_ba Opp_hits  OPP_HR_Column OPP_kk  \\\n",
       "0  0.351351          4           38  0.315789       12              3     11   \n",
       "1  0.342857          3           37  0.378378       14              2     11   \n",
       "2  0.305556          2           37  0.405405       15              3      8   \n",
       "3  0.235294          1            0  0.000000        0              0      0   \n",
       "4  0.305556          3            0  0.000000        0              0      0   \n",
       "\n",
       "    Opp_obp  Opp_walks  \n",
       "0  0.333333          1  \n",
       "1  0.390244          2  \n",
       "2  0.463415          4  \n",
       "3  0.000000          0  \n",
       "4  0.000000          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check imported file\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gm#</th>\n",
       "      <th>W/L</th>\n",
       "      <th>D/N</th>\n",
       "      <th>H/A</th>\n",
       "      <th>Opp</th>\n",
       "      <th>COL_at_bats</th>\n",
       "      <th>COL_ba</th>\n",
       "      <th>COL_hits</th>\n",
       "      <th>COL_hr</th>\n",
       "      <th>COL_kk</th>\n",
       "      <th>COL_obp</th>\n",
       "      <th>COL_walks</th>\n",
       "      <th>Opp_at_bats</th>\n",
       "      <th>Opp_ba</th>\n",
       "      <th>Opp_hits</th>\n",
       "      <th>OPP_HR_Column</th>\n",
       "      <th>OPP_kk</th>\n",
       "      <th>Opp_obp</th>\n",
       "      <th>Opp_walks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>137</td>\n",
       "      <td>8:10 pm</td>\n",
       "      <td>Game Preview and Matchups</td>\n",
       "      <td>H</td>\n",
       "      <td>BAL</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>138</td>\n",
       "      <td>3:10 pm</td>\n",
       "      <td>Game Preview and Matchups</td>\n",
       "      <td>H</td>\n",
       "      <td>BAL</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>139</td>\n",
       "      <td>7:20 pm</td>\n",
       "      <td>Game Preview and Matchups</td>\n",
       "      <td>A</td>\n",
       "      <td>ATL</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>140</td>\n",
       "      <td>7:20 pm</td>\n",
       "      <td>Game Preview and Matchups</td>\n",
       "      <td>A</td>\n",
       "      <td>ATL</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>141</td>\n",
       "      <td>7:20 pm</td>\n",
       "      <td>Game Preview and Matchups</td>\n",
       "      <td>A</td>\n",
       "      <td>ATL</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gm#      W/L                        D/N H/A  Opp  COL_at_bats  COL_ba  \\\n",
       "1816  137  8:10 pm  Game Preview and Matchups   H  BAL           -1    -1.0   \n",
       "1817  138  3:10 pm  Game Preview and Matchups   H  BAL           -1    -1.0   \n",
       "1818  139  7:20 pm  Game Preview and Matchups   A  ATL           -1    -1.0   \n",
       "1819  140  7:20 pm  Game Preview and Matchups   A  ATL           -1    -1.0   \n",
       "1820  141  7:20 pm  Game Preview and Matchups   A  ATL           -1    -1.0   \n",
       "\n",
       "      COL_hits  COL_hr  COL_kk  COL_obp  COL_walks  Opp_at_bats    Opp_ba  \\\n",
       "1816        -1      -1      -1     -1.0         -1           29  0.310345   \n",
       "1817        -1      -1      -1     -1.0         -1           30  0.200000   \n",
       "1818        -1      -1      -1     -1.0         -1           31  0.193548   \n",
       "1819        -1      -1      -1     -1.0         -1           -1 -1.000000   \n",
       "1820        -1      -1      -1     -1.0         -1           -1 -1.000000   \n",
       "\n",
       "     Opp_hits  OPP_HR_Column OPP_kk   Opp_obp  Opp_walks  \n",
       "1816        9              0      9  0.393939          4  \n",
       "1817        6              0     11  0.250000          2  \n",
       "1818       -1              0     -1  0.218750         -1  \n",
       "1819       -1             -1     -1 -1.000000         -1  \n",
       "1820       -1             -1     -1 -1.000000         -1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check imported file\n",
    "unplayed_games_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the \"Opp\" column, so that we dont have to encode all the team names. \n",
    "# Not all teams that are in the model df \"df\" exist in the prediction df \"unplayed_games_clean\"\n",
    "# this ensures that the same number of features are used between creating the RF model and predicting\n",
    "\n",
    "df = df.copy().drop(columns=\"Opp\")\n",
    "\n",
    "\n",
    "# drop Opp later in \"unplayed_games_clean\" in the code, after this column is no longer needed for season calcuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model df columns = Index(['Gm#', 'W/L', 'D/N', 'H/A', 'COL_at_bats', 'COL_ba', 'COL_hits',\n",
      "       'COL_hr', 'COL_kk', 'COL_obp', 'COL_walks', 'Opp_at_bats', 'Opp_ba',\n",
      "       'Opp_hits', 'OPP_HR_Column', 'OPP_kk', 'Opp_obp', 'Opp_walks'],\n",
      "      dtype='object')\n",
      "\n",
      "Prediction df columns = Index(['Gm#', 'W/L', 'D/N', 'H/A', 'Opp', 'COL_at_bats', 'COL_ba', 'COL_hits',\n",
      "       'COL_hr', 'COL_kk', 'COL_obp', 'COL_walks', 'Opp_at_bats', 'Opp_ba',\n",
      "       'Opp_hits', 'OPP_HR_Column', 'OPP_kk', 'Opp_obp', 'Opp_walks'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model df columns = {df.columns}\")\n",
    "print()\n",
    "print(f\"Prediction df columns = {unplayed_games_clean.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gm#                int64\n",
       "W/L               object\n",
       "D/N               object\n",
       "H/A               object\n",
       "COL_at_bats        int64\n",
       "COL_ba           float64\n",
       "COL_hits           int64\n",
       "COL_hr             int64\n",
       "COL_kk             int64\n",
       "COL_obp          float64\n",
       "COL_walks          int64\n",
       "Opp_at_bats        int64\n",
       "Opp_ba           float64\n",
       "Opp_hits          object\n",
       "OPP_HR_Column      int64\n",
       "OPP_kk            object\n",
       "Opp_obp          float64\n",
       "Opp_walks          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data types\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"OPP_HR_Column\": \"Opp_hr\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L' 'W']\n"
     ]
    }
   ],
   "source": [
    "# confirm there are only 2 values in the win/loss column\n",
    "uniquevalues = df[\"W/L\"].unique()\n",
    "print(uniquevalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode object columns as needed\n",
    "# intialize encoders\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gm#</th>\n",
       "      <th>W/L</th>\n",
       "      <th>D/N</th>\n",
       "      <th>H/A</th>\n",
       "      <th>COL_at_bats</th>\n",
       "      <th>COL_ba</th>\n",
       "      <th>COL_hits</th>\n",
       "      <th>COL_hr</th>\n",
       "      <th>COL_kk</th>\n",
       "      <th>COL_obp</th>\n",
       "      <th>COL_walks</th>\n",
       "      <th>Opp_at_bats</th>\n",
       "      <th>Opp_ba</th>\n",
       "      <th>Opp_hits</th>\n",
       "      <th>Opp_hr</th>\n",
       "      <th>OPP_kk</th>\n",
       "      <th>Opp_obp</th>\n",
       "      <th>Opp_walks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1751 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gm#  W/L  D/N  H/A  COL_at_bats    COL_ba  COL_hits  COL_hr  COL_kk  \\\n",
       "0       1    0    0    0           31  0.258065         8       1       8   \n",
       "1       2    1    1    0           32  0.281250         9       1       5   \n",
       "2       3    1    1    0           34  0.264706         9       1       5   \n",
       "3       4    1    0    1           33  0.212121         7       0       8   \n",
       "4       5    1    1    1           33  0.242424         8       0       4   \n",
       "...   ...  ...  ...  ...          ...       ...       ...     ...     ...   \n",
       "1808  129    0    1    0           28  0.178571         5       2       5   \n",
       "1809  130    1    0    0           29  0.172414         5       1       9   \n",
       "1810  131    0    0    0           35  0.342857        12       5       6   \n",
       "1811  132    1    1    1           34  0.264706         9       0       8   \n",
       "1812  133    0    1    1           35  0.342857        12       2       5   \n",
       "\n",
       "       COL_obp  COL_walks  Opp_at_bats    Opp_ba Opp_hits  Opp_hr OPP_kk  \\\n",
       "0     0.351351          4           38  0.315789       12       3     11   \n",
       "1     0.342857          3           37  0.378378       14       2     11   \n",
       "2     0.305556          2           37  0.405405       15       3      8   \n",
       "3     0.235294          1            0  0.000000        0       0      0   \n",
       "4     0.305556          3            0  0.000000        0       0      0   \n",
       "...        ...        ...          ...       ...      ...     ...    ...   \n",
       "1808  0.233333          2           31  0.129032        4       0      9   \n",
       "1809  0.294118          4           39  0.333333       13       2     14   \n",
       "1810  0.410256          3           29  0.206897        6       0      8   \n",
       "1811  0.324324          3           28  0.214286        6       1     11   \n",
       "1812  0.428571          6           34  0.382353       13       4      8   \n",
       "\n",
       "       Opp_obp  Opp_walks  \n",
       "0     0.333333          1  \n",
       "1     0.390244          2  \n",
       "2     0.463415          4  \n",
       "3     0.000000          0  \n",
       "4     0.000000          0  \n",
       "...        ...        ...  \n",
       "1808  0.205882          3  \n",
       "1809  0.386364          4  \n",
       "1810  0.323529          5  \n",
       "1811  0.312500          4  \n",
       "1812  0.405405          1  \n",
       "\n",
       "[1751 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode columns with only 2 unique values\n",
    "df[\"D/N\"] = le.fit_transform(df[\"D/N\"])\n",
    "df[\"H/A\"] = le.fit_transform(df[\"H/A\"])\n",
    "df[\"W/L\"] = le.fit_transform(df[\"W/L\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indices of 'error' values:\n",
      "[(37, 15), (1118, 13)]\n"
     ]
    }
   ],
   "source": [
    "# debug: Locate the positions of \"error\"\n",
    "error_positions = df.isin(['error'])\n",
    "\n",
    "# get the indices of \"error\" values\n",
    "error_indices = [(row, col) for row, col in zip(*error_positions.to_numpy().nonzero())]\n",
    "\n",
    "# Display the indices\n",
    "print(\"\\nIndices of 'error' values:\")\n",
    "print(error_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply new values to those data cells\n",
    "df.iloc[37, 15] = 0\n",
    "df.iloc[1118, 13] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure column values are numerical\n",
    "df['OPP_kk'] = pd.to_numeric(df['OPP_kk'], errors='coerce')\n",
    "df['Opp_hits'] = pd.to_numeric(df['Opp_hits'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gm#              int64\n",
       "W/L              int32\n",
       "D/N              int32\n",
       "H/A              int32\n",
       "COL_at_bats      int64\n",
       "COL_ba         float64\n",
       "COL_hits         int64\n",
       "COL_hr           int64\n",
       "COL_kk           int64\n",
       "COL_obp        float64\n",
       "COL_walks        int64\n",
       "Opp_at_bats      int64\n",
       "Opp_ba         float64\n",
       "Opp_hits         int64\n",
       "Opp_hr           int64\n",
       "OPP_kk           int64\n",
       "Opp_obp        float64\n",
       "Opp_walks        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dtypes for all columns again\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1751"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get target variable (\"win/loss\" column) - y \n",
    "y = df[\"W/L\"]\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gm#</th>\n",
       "      <th>D/N</th>\n",
       "      <th>H/A</th>\n",
       "      <th>COL_at_bats</th>\n",
       "      <th>COL_ba</th>\n",
       "      <th>COL_hits</th>\n",
       "      <th>COL_hr</th>\n",
       "      <th>COL_kk</th>\n",
       "      <th>COL_obp</th>\n",
       "      <th>COL_walks</th>\n",
       "      <th>Opp_at_bats</th>\n",
       "      <th>Opp_ba</th>\n",
       "      <th>Opp_hits</th>\n",
       "      <th>Opp_hr</th>\n",
       "      <th>OPP_kk</th>\n",
       "      <th>Opp_obp</th>\n",
       "      <th>Opp_walks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1751 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gm#  D/N  H/A  COL_at_bats    COL_ba  COL_hits  COL_hr  COL_kk  \\\n",
       "0       1    0    0           31  0.258065         8       1       8   \n",
       "1       2    1    0           32  0.281250         9       1       5   \n",
       "2       3    1    0           34  0.264706         9       1       5   \n",
       "3       4    0    1           33  0.212121         7       0       8   \n",
       "4       5    1    1           33  0.242424         8       0       4   \n",
       "...   ...  ...  ...          ...       ...       ...     ...     ...   \n",
       "1808  129    1    0           28  0.178571         5       2       5   \n",
       "1809  130    0    0           29  0.172414         5       1       9   \n",
       "1810  131    0    0           35  0.342857        12       5       6   \n",
       "1811  132    1    1           34  0.264706         9       0       8   \n",
       "1812  133    1    1           35  0.342857        12       2       5   \n",
       "\n",
       "       COL_obp  COL_walks  Opp_at_bats    Opp_ba  Opp_hits  Opp_hr  OPP_kk  \\\n",
       "0     0.351351          4           38  0.315789        12       3      11   \n",
       "1     0.342857          3           37  0.378378        14       2      11   \n",
       "2     0.305556          2           37  0.405405        15       3       8   \n",
       "3     0.235294          1            0  0.000000         0       0       0   \n",
       "4     0.305556          3            0  0.000000         0       0       0   \n",
       "...        ...        ...          ...       ...       ...     ...     ...   \n",
       "1808  0.233333          2           31  0.129032         4       0       9   \n",
       "1809  0.294118          4           39  0.333333        13       2      14   \n",
       "1810  0.410256          3           29  0.206897         6       0       8   \n",
       "1811  0.324324          3           28  0.214286         6       1      11   \n",
       "1812  0.428571          6           34  0.382353        13       4       8   \n",
       "\n",
       "       Opp_obp  Opp_walks  \n",
       "0     0.333333          1  \n",
       "1     0.390244          2  \n",
       "2     0.463415          4  \n",
       "3     0.000000          0  \n",
       "4     0.000000          0  \n",
       "...        ...        ...  \n",
       "1808  0.205882          3  \n",
       "1809  0.386364          4  \n",
       "1810  0.323529          5  \n",
       "1811  0.312500          4  \n",
       "1812  0.405405          1  \n",
       "\n",
       "[1751 rows x 17 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the features - X\n",
    "X = df.copy()\n",
    "X =X.drop(columns = \"W/L\", axis =1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gm#', 'D/N', 'H/A', 'COL_at_bats', 'COL_ba', 'COL_hits', 'COL_hr',\n",
       "       'COL_kk', 'COL_obp', 'COL_walks', 'Opp_at_bats', 'Opp_ba', 'Opp_hits',\n",
       "       'Opp_hr', 'OPP_kk', 'Opp_obp', 'Opp_walks'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split and scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5)\n",
    "# 9, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data!\n",
    "# Initialize the scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the same parameters\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elcoo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m72\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m72\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m72\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">369</span> (1.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m369\u001b[0m (1.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">369</span> (1.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m369\u001b[0m (1.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number_input_features = len(X_train.columns)\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 = 8\n",
    "hidden_nodes_layer3 = 8\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# fourth hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 0.4088 - loss: 0.7972\n",
      "Epoch 2/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.4647 - loss: 0.7119\n",
      "Epoch 3/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.6000 - loss: 0.6844\n",
      "Epoch 4/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.6700 - loss: 0.6686\n",
      "Epoch 5/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.7027 - loss: 0.6514\n",
      "Epoch 6/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.6723 - loss: 0.6411\n",
      "Epoch 7/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6974 - loss: 0.6157 \n",
      "Epoch 8/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.7077 - loss: 0.5871\n",
      "Epoch 9/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.6975 - loss: 0.5778\n",
      "Epoch 10/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.7120 - loss: 0.5440\n",
      "Epoch 11/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.7494 - loss: 0.4966\n",
      "Epoch 12/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.7779 - loss: 0.4819\n",
      "Epoch 13/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.7811 - loss: 0.4537\n",
      "Epoch 14/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.8059 - loss: 0.4291\n",
      "Epoch 15/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.7978 - loss: 0.4167\n",
      "Epoch 16/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.8046 - loss: 0.4241\n",
      "Epoch 17/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8127 - loss: 0.3927\n",
      "Epoch 18/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.8086 - loss: 0.4134\n",
      "Epoch 19/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.8328 - loss: 0.3825\n",
      "Epoch 20/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.8092 - loss: 0.4205\n",
      "Epoch 21/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.8246 - loss: 0.3800\n",
      "Epoch 22/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.8376 - loss: 0.3683\n",
      "Epoch 23/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.8146 - loss: 0.4028\n",
      "Epoch 24/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.8096 - loss: 0.4061\n",
      "Epoch 25/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.8165 - loss: 0.3820\n",
      "Epoch 26/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.8223 - loss: 0.3950\n",
      "Epoch 27/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.8273 - loss: 0.3711\n",
      "Epoch 28/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.8315 - loss: 0.3650\n",
      "Epoch 29/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.8357 - loss: 0.3755\n",
      "Epoch 30/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.8208 - loss: 0.3711\n",
      "Epoch 31/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.8516 - loss: 0.3437\n",
      "Epoch 32/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.8292 - loss: 0.3737\n",
      "Epoch 33/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.8466 - loss: 0.3453\n",
      "Epoch 34/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.8231 - loss: 0.3695\n",
      "Epoch 35/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.8235 - loss: 0.3772\n",
      "Epoch 36/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.8229 - loss: 0.3777\n",
      "Epoch 37/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.8333 - loss: 0.3709\n",
      "Epoch 38/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.8309 - loss: 0.3500\n",
      "Epoch 39/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.8284 - loss: 0.3520\n",
      "Epoch 40/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8250 - loss: 0.3523 \n",
      "Epoch 41/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.8496 - loss: 0.3572\n",
      "Epoch 42/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8195 - loss: 0.3864\n",
      "Epoch 43/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.8345 - loss: 0.3548\n",
      "Epoch 44/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8372 - loss: 0.3538\n",
      "Epoch 45/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.8235 - loss: 0.3835\n",
      "Epoch 46/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.8266 - loss: 0.3651\n",
      "Epoch 47/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.8285 - loss: 0.3696\n",
      "Epoch 48/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.8474 - loss: 0.3329\n",
      "Epoch 49/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.8472 - loss: 0.3347\n",
      "Epoch 50/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.8459 - loss: 0.3416\n",
      "Epoch 51/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.8436 - loss: 0.3370\n",
      "Epoch 52/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.8424 - loss: 0.3405\n",
      "Epoch 53/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.8452 - loss: 0.3331\n",
      "Epoch 54/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8531 - loss: 0.3260\n",
      "Epoch 55/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8353 - loss: 0.3527\n",
      "Epoch 56/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.8492 - loss: 0.3305\n",
      "Epoch 57/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.8441 - loss: 0.3413\n",
      "Epoch 58/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.8508 - loss: 0.3315\n",
      "Epoch 59/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.8423 - loss: 0.3480\n",
      "Epoch 60/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.8552 - loss: 0.3213\n",
      "Epoch 61/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8388 - loss: 0.3220 \n",
      "Epoch 62/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.8201 - loss: 0.3601\n",
      "Epoch 63/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.8388 - loss: 0.3542\n",
      "Epoch 64/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.8337 - loss: 0.3393\n",
      "Epoch 65/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.8445 - loss: 0.3415\n",
      "Epoch 66/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.8536 - loss: 0.3229\n",
      "Epoch 67/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.8437 - loss: 0.3370\n",
      "Epoch 68/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.3469 \n",
      "Epoch 69/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.8354 - loss: 0.3399\n",
      "Epoch 70/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.8599 - loss: 0.3174\n",
      "Epoch 71/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.8489 - loss: 0.3320\n",
      "Epoch 72/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.8438 - loss: 0.3388\n",
      "Epoch 73/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.8478 - loss: 0.3323\n",
      "Epoch 74/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8540 - loss: 0.3235\n",
      "Epoch 75/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.8550 - loss: 0.3332\n",
      "Epoch 76/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.8562 - loss: 0.3054\n",
      "Epoch 77/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.8473 - loss: 0.3348\n",
      "Epoch 78/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.8422 - loss: 0.3267\n",
      "Epoch 79/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.8394 - loss: 0.3571\n",
      "Epoch 80/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.8658 - loss: 0.3044\n",
      "Epoch 81/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.8560 - loss: 0.3228\n",
      "Epoch 82/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.8479 - loss: 0.3173\n",
      "Epoch 83/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.8551 - loss: 0.3275\n",
      "Epoch 84/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.8491 - loss: 0.3350\n",
      "Epoch 85/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.8512 - loss: 0.3231\n",
      "Epoch 86/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.8315 - loss: 0.3514\n",
      "Epoch 87/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.8553 - loss: 0.3216\n",
      "Epoch 88/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8572 - loss: 0.3036\n",
      "Epoch 89/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.8522 - loss: 0.3234\n",
      "Epoch 90/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.8499 - loss: 0.3294\n",
      "Epoch 91/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.8426 - loss: 0.3278\n",
      "Epoch 92/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.8389 - loss: 0.3169\n",
      "Epoch 93/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.8569 - loss: 0.3085\n",
      "Epoch 94/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.8431 - loss: 0.3323\n",
      "Epoch 95/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.8554 - loss: 0.3253\n",
      "Epoch 96/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.8548 - loss: 0.3306\n",
      "Epoch 97/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.8601 - loss: 0.2940\n",
      "Epoch 98/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.8470 - loss: 0.3313\n",
      "Epoch 99/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.8332 - loss: 0.3422\n",
      "Epoch 100/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.8435 - loss: 0.3239\n",
      "Epoch 101/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.8329 - loss: 0.3299\n",
      "Epoch 102/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8520 - loss: 0.3245 \n",
      "Epoch 103/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.8595 - loss: 0.3027\n",
      "Epoch 104/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.8585 - loss: 0.3127\n",
      "Epoch 105/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.8476 - loss: 0.3232\n",
      "Epoch 106/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.8464 - loss: 0.3179\n",
      "Epoch 107/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.8482 - loss: 0.3318\n",
      "Epoch 108/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.8537 - loss: 0.3191\n",
      "Epoch 109/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.8464 - loss: 0.3217\n",
      "Epoch 110/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.8440 - loss: 0.3090\n",
      "Epoch 111/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.8523 - loss: 0.3106\n",
      "Epoch 112/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.8443 - loss: 0.3365\n",
      "Epoch 113/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.8460 - loss: 0.3145\n",
      "Epoch 114/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.8661 - loss: 0.3009\n",
      "Epoch 115/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.8586 - loss: 0.3135\n",
      "Epoch 116/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8510 - loss: 0.3025 \n",
      "Epoch 117/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.8604 - loss: 0.3230\n",
      "Epoch 118/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.8472 - loss: 0.3092\n",
      "Epoch 119/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.8569 - loss: 0.3233\n",
      "Epoch 120/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.8538 - loss: 0.3123\n",
      "Epoch 121/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.8405 - loss: 0.3251\n",
      "Epoch 122/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8479 - loss: 0.3071\n",
      "Epoch 123/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.8546 - loss: 0.3012\n",
      "Epoch 124/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.8446 - loss: 0.3092\n",
      "Epoch 125/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.8522 - loss: 0.3204\n",
      "Epoch 126/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.8449 - loss: 0.3297\n",
      "Epoch 127/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.8484 - loss: 0.3169\n",
      "Epoch 128/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.8521 - loss: 0.3181\n",
      "Epoch 129/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.8444 - loss: 0.3100\n",
      "Epoch 130/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.8555 - loss: 0.3044\n",
      "Epoch 131/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.8532 - loss: 0.3059\n",
      "Epoch 132/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.8393 - loss: 0.3252\n",
      "Epoch 133/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.8455 - loss: 0.3328\n",
      "Epoch 134/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.8641 - loss: 0.3008\n",
      "Epoch 135/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.8583 - loss: 0.3036\n",
      "Epoch 136/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.8522 - loss: 0.3033\n",
      "Epoch 137/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8600 - loss: 0.3017 \n",
      "Epoch 138/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8627 - loss: 0.3053\n",
      "Epoch 139/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.8569 - loss: 0.3067\n",
      "Epoch 140/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.3096\n",
      "Epoch 141/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.8612 - loss: 0.3110\n",
      "Epoch 142/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.8422 - loss: 0.3165\n",
      "Epoch 143/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.8441 - loss: 0.3209\n",
      "Epoch 144/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8506 - loss: 0.3052\n",
      "Epoch 145/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8561 - loss: 0.2941\n",
      "Epoch 146/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.8629 - loss: 0.3019\n",
      "Epoch 147/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.8426 - loss: 0.3168\n",
      "Epoch 148/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.8451 - loss: 0.3131\n",
      "Epoch 149/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.8493 - loss: 0.2984\n",
      "Epoch 150/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.8416 - loss: 0.3090\n",
      "Epoch 151/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.8594 - loss: 0.2964\n",
      "Epoch 152/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.8402 - loss: 0.3339\n",
      "Epoch 153/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.8555 - loss: 0.3016\n",
      "Epoch 154/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.8688 - loss: 0.2852\n",
      "Epoch 155/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.8524 - loss: 0.3074\n",
      "Epoch 156/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8679 - loss: 0.2978\n",
      "Epoch 157/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.8597 - loss: 0.2857\n",
      "Epoch 158/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.8458 - loss: 0.3168\n",
      "Epoch 159/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.8538 - loss: 0.3048\n",
      "Epoch 160/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.8681 - loss: 0.3010\n",
      "Epoch 161/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.8584 - loss: 0.3078\n",
      "Epoch 162/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.8704 - loss: 0.2815\n",
      "Epoch 163/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8545 - loss: 0.3121 \n",
      "Epoch 164/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.8495 - loss: 0.3151\n",
      "Epoch 165/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.8556 - loss: 0.3094\n",
      "Epoch 166/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8568 - loss: 0.3144\n",
      "Epoch 167/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.8614 - loss: 0.3037\n",
      "Epoch 168/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.8651 - loss: 0.2898\n",
      "Epoch 169/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.8561 - loss: 0.3265\n",
      "Epoch 170/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.8566 - loss: 0.2925\n",
      "Epoch 171/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.8559 - loss: 0.3042\n",
      "Epoch 172/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.8445 - loss: 0.3068\n",
      "Epoch 173/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.8487 - loss: 0.3240\n",
      "Epoch 174/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.8495 - loss: 0.3019\n",
      "Epoch 175/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.8588 - loss: 0.2954\n",
      "Epoch 176/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.8533 - loss: 0.3191\n",
      "Epoch 177/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.8436 - loss: 0.3220\n",
      "Epoch 178/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8480 - loss: 0.3053\n",
      "Epoch 179/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.8600 - loss: 0.3033\n",
      "Epoch 180/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.8590 - loss: 0.2920\n",
      "Epoch 181/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.8466 - loss: 0.3081\n",
      "Epoch 182/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.8668 - loss: 0.2932\n",
      "Epoch 183/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.8524 - loss: 0.3112\n",
      "Epoch 184/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.8592 - loss: 0.2896\n",
      "Epoch 185/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.8566 - loss: 0.2888\n",
      "Epoch 186/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.8508 - loss: 0.3092\n",
      "Epoch 187/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.8596 - loss: 0.2884\n",
      "Epoch 188/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.8684 - loss: 0.2715\n",
      "Epoch 189/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.8572 - loss: 0.3075\n",
      "Epoch 190/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8611 - loss: 0.3154 \n",
      "Epoch 191/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.8661 - loss: 0.2795\n",
      "Epoch 192/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.8700 - loss: 0.2815\n",
      "Epoch 193/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.8548 - loss: 0.3246\n",
      "Epoch 194/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.8437 - loss: 0.3170\n",
      "Epoch 195/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.8671 - loss: 0.3015\n",
      "Epoch 196/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.8604 - loss: 0.3117\n",
      "Epoch 197/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.8530 - loss: 0.2950\n",
      "Epoch 198/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8686 - loss: 0.2919\n",
      "Epoch 199/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.8526 - loss: 0.3124\n",
      "Epoch 200/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.8576 - loss: 0.2946\n"
     ]
    }
   ],
   "source": [
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hypertune model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation',['relu','tanh','sigmoid'])\n",
    "\n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=1,\n",
    "        max_value=10,\n",
    "        step=2), activation=activation, input_dim=len(X_train.columns)))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 6)):\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=1,\n",
    "            max_value=10,\n",
    "            step=2),\n",
    "            activation=activation))\n",
    "\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the kerastuner library\n",
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=100,\n",
    "    hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the kerastuner search for best hyperparameters\n",
    "tuner.search(X_train_scaled,y_train,epochs=100,validation_data=(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model hyperparameters\n",
    "best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "best_hyper.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate best model against full test data\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "model_loss, model_accuracy = best_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load unplayed game csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gm#</th>\n",
       "      <th>W/L</th>\n",
       "      <th>D/N</th>\n",
       "      <th>H/A</th>\n",
       "      <th>COL_at_bats</th>\n",
       "      <th>COL_ba</th>\n",
       "      <th>COL_hits</th>\n",
       "      <th>COL_hr</th>\n",
       "      <th>COL_kk</th>\n",
       "      <th>COL_obp</th>\n",
       "      <th>COL_walks</th>\n",
       "      <th>Opp_at_bats</th>\n",
       "      <th>Opp_ba</th>\n",
       "      <th>Opp_hits</th>\n",
       "      <th>OPP_kk</th>\n",
       "      <th>Opp_obp</th>\n",
       "      <th>Opp_walks</th>\n",
       "      <th>Opp_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>34.173611</td>\n",
       "      <td>0.253</td>\n",
       "      <td>8.548611</td>\n",
       "      <td>8.256944</td>\n",
       "      <td>0.316</td>\n",
       "      <td>3.020833</td>\n",
       "      <td>1.451389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>34.173611</td>\n",
       "      <td>0.253</td>\n",
       "      <td>8.548611</td>\n",
       "      <td>8.256944</td>\n",
       "      <td>0.316</td>\n",
       "      <td>3.020833</td>\n",
       "      <td>1.451389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.272727</td>\n",
       "      <td>0.245</td>\n",
       "      <td>8.020979</td>\n",
       "      <td>8.993007</td>\n",
       "      <td>0.306</td>\n",
       "      <td>2.937063</td>\n",
       "      <td>1.265734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.272727</td>\n",
       "      <td>0.245</td>\n",
       "      <td>8.020979</td>\n",
       "      <td>8.993007</td>\n",
       "      <td>0.306</td>\n",
       "      <td>2.937063</td>\n",
       "      <td>1.265734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.272727</td>\n",
       "      <td>0.245</td>\n",
       "      <td>8.020979</td>\n",
       "      <td>8.993007</td>\n",
       "      <td>0.306</td>\n",
       "      <td>2.937063</td>\n",
       "      <td>1.265734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.832168</td>\n",
       "      <td>0.278</td>\n",
       "      <td>8.454545</td>\n",
       "      <td>8.853147</td>\n",
       "      <td>0.328</td>\n",
       "      <td>3.741259</td>\n",
       "      <td>1.118881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.832168</td>\n",
       "      <td>0.278</td>\n",
       "      <td>8.454545</td>\n",
       "      <td>8.853147</td>\n",
       "      <td>0.328</td>\n",
       "      <td>3.741259</td>\n",
       "      <td>1.118881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.832168</td>\n",
       "      <td>0.278</td>\n",
       "      <td>8.454545</td>\n",
       "      <td>8.853147</td>\n",
       "      <td>0.328</td>\n",
       "      <td>3.741259</td>\n",
       "      <td>1.118881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.361111</td>\n",
       "      <td>0.191</td>\n",
       "      <td>7.812500</td>\n",
       "      <td>8.805556</td>\n",
       "      <td>0.298</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>1.006944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.361111</td>\n",
       "      <td>0.191</td>\n",
       "      <td>7.812500</td>\n",
       "      <td>8.805556</td>\n",
       "      <td>0.298</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>1.006944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.361111</td>\n",
       "      <td>0.191</td>\n",
       "      <td>7.812500</td>\n",
       "      <td>8.805556</td>\n",
       "      <td>0.298</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>1.006944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.482517</td>\n",
       "      <td>0.230</td>\n",
       "      <td>7.986014</td>\n",
       "      <td>8.531469</td>\n",
       "      <td>0.314</td>\n",
       "      <td>3.342657</td>\n",
       "      <td>1.041958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.482517</td>\n",
       "      <td>0.230</td>\n",
       "      <td>7.986014</td>\n",
       "      <td>8.531469</td>\n",
       "      <td>0.314</td>\n",
       "      <td>3.342657</td>\n",
       "      <td>1.041958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.482517</td>\n",
       "      <td>0.230</td>\n",
       "      <td>7.986014</td>\n",
       "      <td>8.531469</td>\n",
       "      <td>0.314</td>\n",
       "      <td>3.342657</td>\n",
       "      <td>1.041958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>34.048611</td>\n",
       "      <td>0.262</td>\n",
       "      <td>8.916667</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>0.335</td>\n",
       "      <td>3.479167</td>\n",
       "      <td>1.270833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>34.048611</td>\n",
       "      <td>0.262</td>\n",
       "      <td>8.916667</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>0.335</td>\n",
       "      <td>3.479167</td>\n",
       "      <td>1.270833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>34.048611</td>\n",
       "      <td>0.262</td>\n",
       "      <td>8.916667</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>0.335</td>\n",
       "      <td>3.479167</td>\n",
       "      <td>1.270833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.993007</td>\n",
       "      <td>0.247</td>\n",
       "      <td>8.622378</td>\n",
       "      <td>8.405594</td>\n",
       "      <td>0.330</td>\n",
       "      <td>3.629371</td>\n",
       "      <td>1.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.993007</td>\n",
       "      <td>0.247</td>\n",
       "      <td>8.622378</td>\n",
       "      <td>8.405594</td>\n",
       "      <td>0.330</td>\n",
       "      <td>3.629371</td>\n",
       "      <td>1.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.993007</td>\n",
       "      <td>0.247</td>\n",
       "      <td>8.622378</td>\n",
       "      <td>8.405594</td>\n",
       "      <td>0.330</td>\n",
       "      <td>3.629371</td>\n",
       "      <td>1.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>34.006993</td>\n",
       "      <td>0.262</td>\n",
       "      <td>8.384615</td>\n",
       "      <td>8.195804</td>\n",
       "      <td>0.310</td>\n",
       "      <td>2.916084</td>\n",
       "      <td>1.027972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>34.006993</td>\n",
       "      <td>0.262</td>\n",
       "      <td>8.384615</td>\n",
       "      <td>8.195804</td>\n",
       "      <td>0.310</td>\n",
       "      <td>2.916084</td>\n",
       "      <td>1.027972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>34.006993</td>\n",
       "      <td>0.262</td>\n",
       "      <td>8.384615</td>\n",
       "      <td>8.195804</td>\n",
       "      <td>0.310</td>\n",
       "      <td>2.916084</td>\n",
       "      <td>1.027972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.993007</td>\n",
       "      <td>0.247</td>\n",
       "      <td>8.622378</td>\n",
       "      <td>8.405594</td>\n",
       "      <td>0.330</td>\n",
       "      <td>3.629371</td>\n",
       "      <td>1.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.993007</td>\n",
       "      <td>0.247</td>\n",
       "      <td>8.622378</td>\n",
       "      <td>8.405594</td>\n",
       "      <td>0.330</td>\n",
       "      <td>3.629371</td>\n",
       "      <td>1.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.011422</td>\n",
       "      <td>0.278016</td>\n",
       "      <td>9.374643</td>\n",
       "      <td>1.205026</td>\n",
       "      <td>7.342661</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>3.214163</td>\n",
       "      <td>33.993007</td>\n",
       "      <td>0.247</td>\n",
       "      <td>8.622378</td>\n",
       "      <td>8.405594</td>\n",
       "      <td>0.330</td>\n",
       "      <td>3.629371</td>\n",
       "      <td>1.363636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gm#  W/L  D/N  H/A  COL_at_bats    COL_ba  COL_hits    COL_hr    COL_kk  \\\n",
       "0   137  NaN    1    1    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "1   138  NaN    0    1    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "2   139  NaN    1    0    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "3   140  NaN    1    0    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "4   141  NaN    1    0    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "5   142  NaN    1    0    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "6   143  NaN    1    0    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "7   144  NaN    0    0    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "8   145  NaN    1    0    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "9   146  NaN    1    0    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "10  147  NaN    0    0    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "11  148  NaN    1    1    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "12  149  NaN    1    1    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "13  150  NaN    0    1    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "14  151  NaN    1    1    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "15  152  NaN    1    1    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "16  153  NaN    0    1    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "17  154  NaN    1    0    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "18  155  NaN    1    0    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "19  156  NaN    0    0    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "20  157  NaN    1    1    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "21  158  NaN    1    1    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "22  159  NaN    0    1    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "23  160  NaN    1    1    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "24  161  NaN    1    1    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "25  162  NaN    0    1    33.011422  0.278016  9.374643  1.205026  7.342661   \n",
       "\n",
       "     COL_obp  COL_walks  Opp_at_bats  Opp_ba  Opp_hits    OPP_kk  Opp_obp  \\\n",
       "0   0.344419   3.214163    34.173611   0.253  8.548611  8.256944    0.316   \n",
       "1   0.344419   3.214163    34.173611   0.253  8.548611  8.256944    0.316   \n",
       "2   0.344419   3.214163    33.272727   0.245  8.020979  8.993007    0.306   \n",
       "3   0.344419   3.214163    33.272727   0.245  8.020979  8.993007    0.306   \n",
       "4   0.344419   3.214163    33.272727   0.245  8.020979  8.993007    0.306   \n",
       "5   0.344419   3.214163    33.832168   0.278  8.454545  8.853147    0.328   \n",
       "6   0.344419   3.214163    33.832168   0.278  8.454545  8.853147    0.328   \n",
       "7   0.344419   3.214163    33.832168   0.278  8.454545  8.853147    0.328   \n",
       "8   0.344419   3.214163    33.361111   0.191  7.812500  8.805556    0.298   \n",
       "9   0.344419   3.214163    33.361111   0.191  7.812500  8.805556    0.298   \n",
       "10  0.344419   3.214163    33.361111   0.191  7.812500  8.805556    0.298   \n",
       "11  0.344419   3.214163    33.482517   0.230  7.986014  8.531469    0.314   \n",
       "12  0.344419   3.214163    33.482517   0.230  7.986014  8.531469    0.314   \n",
       "13  0.344419   3.214163    33.482517   0.230  7.986014  8.531469    0.314   \n",
       "14  0.344419   3.214163    34.048611   0.262  8.916667  7.777778    0.335   \n",
       "15  0.344419   3.214163    34.048611   0.262  8.916667  7.777778    0.335   \n",
       "16  0.344419   3.214163    34.048611   0.262  8.916667  7.777778    0.335   \n",
       "17  0.344419   3.214163    33.993007   0.247  8.622378  8.405594    0.330   \n",
       "18  0.344419   3.214163    33.993007   0.247  8.622378  8.405594    0.330   \n",
       "19  0.344419   3.214163    33.993007   0.247  8.622378  8.405594    0.330   \n",
       "20  0.344419   3.214163    34.006993   0.262  8.384615  8.195804    0.310   \n",
       "21  0.344419   3.214163    34.006993   0.262  8.384615  8.195804    0.310   \n",
       "22  0.344419   3.214163    34.006993   0.262  8.384615  8.195804    0.310   \n",
       "23  0.344419   3.214163    33.993007   0.247  8.622378  8.405594    0.330   \n",
       "24  0.344419   3.214163    33.993007   0.247  8.622378  8.405594    0.330   \n",
       "25  0.344419   3.214163    33.993007   0.247  8.622378  8.405594    0.330   \n",
       "\n",
       "    Opp_walks    Opp_hr  \n",
       "0    3.020833  1.451389  \n",
       "1    3.020833  1.451389  \n",
       "2    2.937063  1.265734  \n",
       "3    2.937063  1.265734  \n",
       "4    2.937063  1.265734  \n",
       "5    3.741259  1.118881  \n",
       "6    3.741259  1.118881  \n",
       "7    3.741259  1.118881  \n",
       "8    2.812500  1.006944  \n",
       "9    2.812500  1.006944  \n",
       "10   2.812500  1.006944  \n",
       "11   3.342657  1.041958  \n",
       "12   3.342657  1.041958  \n",
       "13   3.342657  1.041958  \n",
       "14   3.479167  1.270833  \n",
       "15   3.479167  1.270833  \n",
       "16   3.479167  1.270833  \n",
       "17   3.629371  1.363636  \n",
       "18   3.629371  1.363636  \n",
       "19   3.629371  1.363636  \n",
       "20   2.916084  1.027972  \n",
       "21   2.916084  1.027972  \n",
       "22   2.916084  1.027972  \n",
       "23   3.629371  1.363636  \n",
       "24   3.629371  1.363636  \n",
       "25   3.629371  1.363636  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unplayed_games_final = pd.read_csv('../Project 2/randomforest_support_csv_files/unplayed_games_populated.csv')\n",
    "unplayed = unplayed_games[3:].copy()\n",
    "gm_col = unplayed['Gm#'].reset_index(drop=True)\n",
    "unplayed_games_topred = pd.concat([unplayed_games_final, gm_col], axis=1)\n",
    "pop_gm = unplayed_games_topred.pop('Gm#')\n",
    "unplayed_games_topred.insert(0, \"Gm#\", pop_gm)\n",
    "unplayed_games_topred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating Prediction Target Variable from Prediction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get target and features\n",
    "y_to_predict = unplayed_games_topred[\"W/L\"].copy()\n",
    "X_to_predict = unplayed_games_topred.drop(columns=[\"W/L\"]).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Casting Predictions on Prediction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the feature data\n",
    "X_prediction_data = scaler.fit_transform(X_to_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "\n",
    "y_pred = nn.predict(X_prediction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_round = y_pred.round()\n",
    "\n",
    "display(y_round)\n",
    "#len(y_round)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Mini Dataframe to show Game#, Opponent, and Prediction for W/L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the date from original dataframe\n",
    "from mega import mega_concat_df\n",
    "\n",
    "mega_concat_df.columns\n",
    "dates = mega_concat_df['Formatted_Date'].tail(26)\n",
    "opponents = mega_concat_df[\"Opp\"].tail(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equalize all index values for all separate pieces\n",
    "dates = dates.reset_index(drop=True)\n",
    "opponents = opponents.reset_index(drop=True)\n",
    "winloss = pd.DataFrame(y_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Formatted_Date</th>\n",
       "      <th>Opp</th>\n",
       "      <th>Win/Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>BAL</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>BAL</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>ATL</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-04</td>\n",
       "      <td>ATL</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-05</td>\n",
       "      <td>ATL</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-09-06</td>\n",
       "      <td>MIL</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-09-07</td>\n",
       "      <td>MIL</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-09-08</td>\n",
       "      <td>MIL</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-09-10</td>\n",
       "      <td>DET</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-09-11</td>\n",
       "      <td>DET</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-09-12</td>\n",
       "      <td>DET</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-09-13</td>\n",
       "      <td>CHC</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-09-14</td>\n",
       "      <td>CHC</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024-09-15</td>\n",
       "      <td>CHC</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024-09-16</td>\n",
       "      <td>ARI</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024-09-17</td>\n",
       "      <td>ARI</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024-09-18</td>\n",
       "      <td>ARI</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024-09-20</td>\n",
       "      <td>LAD</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024-09-21</td>\n",
       "      <td>LAD</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2024-09-22</td>\n",
       "      <td>LAD</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2024-09-24</td>\n",
       "      <td>STL</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2024-09-25</td>\n",
       "      <td>STL</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2024-09-26</td>\n",
       "      <td>STL</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2024-09-27</td>\n",
       "      <td>LAD</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2024-09-28</td>\n",
       "      <td>LAD</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2024-09-29</td>\n",
       "      <td>LAD</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Formatted_Date  Opp Win/Loss\n",
       "0      2024-08-31  BAL     loss\n",
       "1      2024-09-01  BAL     loss\n",
       "2      2024-09-03  ATL      win\n",
       "3      2024-09-04  ATL      win\n",
       "4      2024-09-05  ATL      win\n",
       "5      2024-09-06  MIL      win\n",
       "6      2024-09-07  MIL      win\n",
       "7      2024-09-08  MIL      win\n",
       "8      2024-09-10  DET      win\n",
       "9      2024-09-11  DET      win\n",
       "10     2024-09-12  DET      win\n",
       "11     2024-09-13  CHC     loss\n",
       "12     2024-09-14  CHC     loss\n",
       "13     2024-09-15  CHC     loss\n",
       "14     2024-09-16  ARI     loss\n",
       "15     2024-09-17  ARI     loss\n",
       "16     2024-09-18  ARI     loss\n",
       "17     2024-09-20  LAD     loss\n",
       "18     2024-09-21  LAD     loss\n",
       "19     2024-09-22  LAD     loss\n",
       "20     2024-09-24  STL     loss\n",
       "21     2024-09-25  STL     loss\n",
       "22     2024-09-26  STL     loss\n",
       "23     2024-09-27  LAD     loss\n",
       "24     2024-09-28  LAD     loss\n",
       "25     2024-09-29  LAD     loss"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat and rename columns for new minidataframe\n",
    "predicted_winLoss_df = pd.concat([dates, opponents,winloss], axis=1, )\n",
    "predicted_winLoss_df = predicted_winLoss_df.rename(columns = {0: \"Win/Loss\"})\n",
    "predicted_winLoss_df['Win/Loss'] = predicted_winLoss_df['Win/Loss'].replace({0:\"loss\", 1:\"win\"})\n",
    "predicted_winLoss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot randomforest tree as a diagram\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# grab list of features from test data \n",
    "feature_list = X.columns.tolist()\n",
    "\n",
    "# Visualize one of the trees from the forest\n",
    "plt.figure(figsize=(240, 80))\n",
    "plot_tree(nn.estimators_[0], feature_names=feature_list, class_names=['Lose[0]', 'Win[1]'], filled=True)\n",
    "plt.title(\"Decision Tree from Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance chart\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Extract feature importances from randomforest model\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Get feature names from the training data\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame using feature names and feature importances \n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance, descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "\n",
    "# Plot the feature importances as a bar chart\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.barh(top_10_features['Feature'], top_10_features['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature at the top\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
